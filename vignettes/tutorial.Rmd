---
title: "Chronicler: History of Objects in R"
author: "Lukasz A. Bartnik"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Chronicler: History of Objects in R}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
library(knitr)
library(utilities)

knitr::opts_chunk$set(collapse = TRUE, comment = NA, prompt = FALSE, echo = TRUE)
```

```{r hooks, echo = FALSE}
options(crayon.enabled = TRUE)
knitr::knit_hooks$set(output = utilities::ansi_handler)
knitr::knit_hooks$set(message = utilities::ansi_handler)

# try old.hooks <- set_knit_hooks(knitr::knit_hooks)

original_output_hook <- knit_hooks$get("output")
knit_hooks$set(output = utilities::create_trimming_hook(original_output_hook))
```

```{r load-chronicler,message=FALSE,include=FALSE}
options(chronicler.attach = FALSE)
library(chronicler)
```


# Introduction

`chronicler` collects all research artifacts (plots, data, models, code)
and their lineage in a file-system-based repository. Such data becomes
handy when you need to to verify the origin (lineage) of an artifact or
browse the artifacts to restore a certain past state of research.

`chronicler` has been designed specifically to introduce only minimal
overhead and to provide additional help only when the R tools of choice
are not sufficient. `chronicler` does not require any changes to the
research process, personal habits of preferences. Users can produce and
organize the results of their work however they choose, and interact
with `chronicler` only when they need to retrieve past data.

This document presents the few foundational concepts of `chronicler`
and provides a few code examples to illustrate their relevance in data
analysis.


## Docker

You can experiment with `chronicler`, test every idea described in this
vignette and run every code snippet included below. In order to make it
more easier, I created a Docker image which comes with necessary R
packages, their dependencies, sample data and RStudio - all preinstalled,
configured and ready to go.

To run this docker image here is where you get it from; here is how you start it



# Problem

Data exploration and modelling are messy. We start with a bunch of data,
we make a lot of attempts, poke around, do our best to learn anything we
can about that data set, and finally produce a predictive model, a
recommendation for decision makers or simply a description of what is in
the data.

So, what is the "problem"? Why is data exploration "messy", again? It
boils down to one thing: complexity of the learning process. Before the
final outcome is known, a typical researcher will build many intermatied
models, a variety of transformed data sets, a multitude of plots. Some
of them will be useful as intermediate steps towards something more
refined, but many are useful only because they confirm that certain
ideas are wrong.

```{r all-together, echo=FALSE, fig.cap="*Figure 1*: Data modelling is messy: which model is the right one?", out.width = '100%'}
knitr::include_graphics("graphics/all-together.png")
```

OK, but why is that a problem at all? It might be, and usually is,
because data exploration is also iterative, which means frequent
back-and-forth between variuos ideas. And that means you have to have
something to return to: code, data, models, plots. But since you never
know what might turn out handy, it's better to store everything, or at
least as much as possible. But that means a lot of "everything", and
then, where to store it? Not to mention making sure that this piece of
code produces that particular object or plot that I need right now. Data
exploration is as much about harnessing chaos as it is about actual data
exploration. Hence, the messiness.

TODO a picture of stacks of plots, code snippets, table printouts;
 like a stack of photos

There are of course multiple tools and techniques aimed at exactly this
problem. RMarkdown, R and Jupyter notebooks, code versioning (think: git),
to name a few tools, or literate programming and packaging code with unit
tests to name some techniques. Here I want to propose something slightly
different, which combined with existing tools can help with the challenge
of organizing artifacts and findings of a data exploration process.


The approach described here, and provided as the `chronicler` R package,
is built around two main components: an R object tracker and a search
engine. However, because we track not only R objects created and
transformed in R session, but also code, plots and console printouts[^printouts],
from now on we will be talking about __artifacts__ and not __objects__.

[^printouts]: Console printouts are not implemented yet.


## Tracker

Let's start with the artifact tracker. Imagine that the commands below
were run in a new (that is, empty) R session; see `?iris_model` for more
details on this example.

```{r cache=FALSE,include=FALSE}
path <- system.file('scripts/iris-model.R', package = 'repository')
read_chunk(path)
```
```{r iris-model,eval=FALSE}
```


Let's take a look at the artifacts created in each step: which of them
are kept in the session and which stored in the repository. The plot
below depicts artifacts <span style="color: #4fb9ec;">created in R session</span>
and <span style="color: #7bce24;">stored in the repository</span>
as <span style="color: #868686;">R commands</span> are executed.

![*Figure 2*: Objects in R session and artifacts in repository.](graphics/commits.png)

It is important to notice the four-digit (hexadecimal) identifier
assigned to each artifact. Even though artifacts which share name are
replaced in R session (namely, in the global environment), they remain
intact when written into the repository. Furthermore, each command
tracks its parent which means the complete lineage[^lineage] of each
artifacts can be retrieved on request.

The tracker itself is a simple callback function registered in R session
with the standard R API, the `addTaskCallback()` function from the `base`
package. Thus, which is quite crucial, tracker can be loaded and executed
in R entirely out-of-the-box, without any additional configuration or
changes to the environment.


[^lineage]: lineal descent from an ancestor; ancestry or pedigree. Oxford Dictionary of English.


## Search

Tracking artifacts would be quite useless without a proper method to
retrieve those relevant to the ongoing research. One of the core
assumptions in the design of `chronicler` is that it should fit into any
given way of doing research in R. This assumption led us to choose a
file-based search mechanism.

A user points to a file - a plot, a data set, a serialized model - and
`chronicler` finds all artifacts matching the contents of that file.
These artifacts can be then displayed in their specific context, which
includes the R command which created them, their lineage (parent
artifacts).

```{r cache=FALSE,include=FALSE,message=FALSE}
chronicler:::attach_to_repository(iris_model())
```
First, a trivial object search. The `iris` data set is assigned to
variable `x` in the first line of the example.

```{r search-iris}
identify_artifact(iris)
```

Artifact `2b0c3bb1` is indeed a copy of the `iris` data set and a quick
look at the expression confirms that it is the result of the first command
in our example.

Now we will search for a plot stored in a file. `chronicler` contains
such plot, one of the artifacts in the `iris_model()` example. Let's
find the path and see the plot itself.

```{r iris-plot-path}
path <- system.file('artifacts/iris-predictions.png', package = 'chronicler')
```
```{r iris-show-plot,results='asis',echo=FALSE}
cat(sprintf("![Figure 3: Plot stored under chronicler/artifacts/iris-predictions.png](%s)", path))
```

Searching by file contents reveals another artifacts, this time the
first of the two plots from our example. Let's also see what can we
learn about the context in which that plot was run: `explain()` prints
a few entries from the history leading up to the artifact in question.

```{r iris-search}
identify_artifact(path)
explain(identify_artifact(path))
```


So, with `chronicler` tracking your work, you will always be able to
find the exact sequence of commands that led to a plot or a model
sitting somewhere in your project's folder.

## Find Models

A more focused version of search 


# Browsing the Repository

more elaborate example using `london_meters`

```{r attach,include=FALSE}
chronicler:::attach_to_repository(london_meters())
# TODO why does it have to be forwarded like that?
artifacts <- chronicler::artifacts
```

```{r docker-attach,eval=FALSE}
library(chronicler)
attach_with_wizard(london_meters())
```

Code for this example attached in Appendix.


## Exploring the repository of artifacts

We can look at R sessions recorded so far. Below is the list of all R
sessions present in the repository. Each session is represented by an
unique identifier, followed by the timestamp when it was started, and
finally the number of artifacts recorded during that session.

```{r session}
class(artifacts$session)
```


We can also see names of objects recorded in the repository. Each name
is followed by the number of artifacts assigned that name.

```{r name}
artifacts$name
```


Similarly, we can look at the breakdown of artifacts by: `class`, `id`
and `time`. The `time` breakdown does not show the number of artifacts
but allows for a number of more elaborate searches:

```{r time}
artifacts$time
```

## Exploring a recorded R session

In order to see artifacts recorded during a given R session, we need to
specify the session identifier as a part of the query line. When the
result is printed on the console, it first shows the actual query used
to retrieve artifacts, followed by the descriptions of the first three
artifacts, which is finally followed by a simple footer with the number
of artifacts not shown and other tags which can be used to further narrow
the set of artifacts.

```{r}
artifacts$session$d75d3d72
```


We can look at the history of evaluated commands:

```{r}
artifacts$session$d75d3d72$history
```


We can also look at the tree view of the artifacts, where edges of the
tree connect artifacts originating from one another.

```{r}
artifacts$session$d75d3d72$tree
```


Finally, let's limit the displayed artifacts to `data.frame`s and
investigate their structure of origin.

```{r}
artifacts$session$d75d3d72$class$data.frame$tree
```



## Searching for a specific artifact

We can limit the object selection by session identifier:

```{r}
artifacts$session$d75d3d72
```

Similarily, we can look at specific object creation time:

```{r eval=FALSE}
artifacts$time$since_yesterday
```

In both cases, we see a `filter()` expression added to the selection
query and at most the first three objects matching this query.


## Selecting an artifact

We can retrieve a specific artifact from the repository. Let's search for
artifacts whose name is `m`:

```{r}
artifacts$name$m
```

Since there is only one such artifact we can access it by adding `$value`
to the last query.

```{r, output.lines=8}
artifacts$name$m$value
```

If the name is not unique we can use artifact id.

```{r eval=FALSE}
artifacts$id$`57fbe755`$value
```

Unlike other tag names, `name` and `id` do not need to be used explicitly.
Thus, a shortcut version of these queries is:

```{r eval=FALSE}
artifacts$x$value
artifacts$`57fbe755`$value
```

If there is more than one object matching the query we can keep
narrowing the selection:

```{r eval=FALSE}
artifacts$name$y$class$lm$value
```

Similarly, we can construct a query where name or id is not specified
at all.

```{r eval=FALSE}
artifacts$time$yesterday$class$lm
```

Finally, you can use the bracket operator to access an arbitrary
object within a query result:

```{r eval=FALSE}
artifacts$class$data.frame[[1]]
artifacts$class$data.frame[[2]]
```

## Retrieving a plot

Plots are going to be a big part of every data analysis. There is no need
to replot them, which is potentially a time-consuming operation. In order
to retrieve all plots from the repository, run the following code.

```{r}
artifacts$class$plot
```

There is also a shortcut for that operation:

```{r eval=FALSE}
artifacts$plots
```

In order to see the actual plot use the `plot` accessor on one of the
artifacts in the result set:

```{r}
artifacts$class$plot[[1]]$plot
```

You can do the same using the `id` of the plot:

```{r eval=FALSE}
artifacts$ba5bb305$plot
```




